---
title: "Re-Analyzing Ota, Hartsuiker and Haywood (2009): A Bayesian Approach to Representational Indeterminacy"
author:
  - Violet Manson
  - Sandria Tran
date: "December 11, 2025"
format: pdf
---

## Final Reflection

### Proposed Mark and Justification

**Proposed Mark: 85 (A2)**

**Justification:**

We propose a mark of 85 (A2), reflecting a project that is "outstanding in some respects" and demonstrates "original, sophisticated independent thinking." Our work not only successfully replicated the core findings of Ota et al. (2009) [1] using a modern Bayesian framework but also extended the analysis to test the underlying linguistic theory with greater precision. This demonstrates a thorough and sophisticated application of the principles learned in this course.

**1. Understanding of Data Analysis Principles (A2)**

Our project shows a sophisticated understanding of data analysis by translating a frequentist ANOVA into a more robust Bayesian hierarchical logistic regression. This model, specified as `accuracy ~ contrast_type + (1 | subject_id) + (1 | item_id)`, correctly accounts for the nested structure of the data with random intercepts for both subjects and items. Our original thinking is evident in the development of three distinct models:

*   **Comprehensive Model:** Replicated the original design (`accuracy ~ contrast_type`).
*   **Linguistic Model:** Tested the theoretical hierarchy directly (`accuracy ~ phonological_status`).
*   **Distinctness Model:** Quantified the core mechanism with a continuous predictor (`accuracy ~ phonological_distinctness_scaled`).

This multi-model approach allowed us to move beyond simple replication and critically evaluate the linguistic theory itself, demonstrating the "original and sophisticated independent thinking" required for an A2 mark.

**2. Open Scholarship Practices (A2)**

Our work was conducted with a strong commitment to open and reproducible science. The entire analysis is available in a fully documented R script (`TaskA_.r`), and the project will be shared on a public GitHub repository. We explicitly defined and justified our priors (`normal(0, 1.5)` for fixed effects, `exponential(1)` for random effects) to ensure transparency. Furthermore, we validated our models using posterior predictive checks, which confirmed that our simulations accurately captured the distribution of the observed data. This demonstrates a "thorough understanding of Open Scholarship principles" and their practical application.

**3. R Data Analysis Skills (A2)**

We demonstrated advanced proficiency in R throughout the project. We used the `brms` package [2] to specify and fit complex Bayesian models, the `tidyverse` for sophisticated data manipulation (e.g., creating the `phonologically_distinct` and `phonological_status` variables), and `ggplot2` and `tidybayes` to produce 14 publication-quality visualizations. The technical implementation, from data preprocessing to model fitting and visualization, was accurate and efficient, showcasing a command of R that is "very good or excellent in most respects."

### Reflection on QML Experience and Learning Growth

This project was the culmination of our learning in Quantitative Methods in Linguistics. The primary growth area was the transition from a frequentist to a Bayesian mindset. Instead of relying on p-values, we learned to interpret model parameters as full probability distributions, quantify uncertainty with credible intervals, and use posterior predictions to understand our model's implications. This project solidified our understanding of how to connect abstract linguistic theories, like representational indeterminacy, to concrete, testable statistical models. The hands-on experience of building, validating, and interpreting these models has given us a powerful new toolkit for future research.

### Individual Contribution

*   **Violet Manson:** I was responsible for the primary technical implementation. This included writing the R code for data preprocessing, specifying and fitting the three Bayesian models in `brms`, and generating all data visualizations. I also conducted the model validation and sensitivity analyses to ensure the robustness of our findings.

*   **Sandria Tran:** I led the theoretical and narrative development of the project. I conducted the literature review of Ota et al. (2009) [1], framed the research questions, and interpreted the model outputs in the context of linguistic theory. I wrote the final report, ensuring that our statistical results were translated into a clear and compelling argument.

## Group Project Output

### Executive Summary

This project revisits the findings of Ota, Hartsuiker, and Haywood (2009) [1], who investigated how a speaker's native language (L1) phonology affects their perception of a second language (L2). They found that Japanese speakers, whose language lacks an /l/-/r/ distinction, have high error rates when identifying English words with this contrast. We re-analyzed their data using a Bayesian hierarchical logistic regression to provide a more robust and nuanced test of their **representational indeterminacy** hypothesis.

Our Bayesian analysis confirms the original findings with high certainty and provides deeper insight. We found that the odds of an error for the /l/-/r/ contrast were over 10 times higher than for control words. More importantly, our models show that this is not a simple categorical effect but is driven by the continuous variable of **phonological distinctness**, providing strong support for the theoretical mechanism proposed by Ota et al.

### Methods

We used the original dataset from Ota et al. (2009) [1], focusing on the accuracy data from 20 native Japanese speakers in a visual semantic-relatedness task. Our analysis was conducted in R using the `brms` package [2].

Our primary model was a Bayesian hierarchical logistic regression with the formula:

`accuracy ~ contrast_type + (1 | subject_id) + (1 | item_id)`

*   **`accuracy`**: A binary variable (1=correct, 0=error).
*   **`contrast_type`**: A factor with four levels (F, LR, H, PB), with F (spelling control) as the reference level.
*   **`(1 | subject_id)` and `(1 | item_id)`**: Random intercepts to account for baseline variability across subjects and items.

We used weakly informative priors (`normal(0, 1.5)` for fixed effects, `exponential(1)` for random effect standard deviations) to regularize the model while letting the data speak for itself. The model was run with 4 chains for 2000 iterations each, with 1000 warmup iterations.

### Results

Our Bayesian analysis provides robust confirmation of the original findings. The model revealed a large, negative effect on the log-odds of a correct response for both the /l/-/r/ contrast (LR) and for homophones (H) when compared to the spelling control (F). The median error rate for the /l/-/r/ contrast was **21.1%** [95% CrI: 14.2, 30.2], compared to just **1.8%** [95% CrI: 1.0, 3.0] for the control words.

![Predicted error rates with 95% credible intervals for all four contrast types. The /l/-/r/ (LR) and Homophone (H) contrasts show significantly higher error rates than the Spelling Control (F) and /p/-/b/ (PB) contrasts.](outputs/10_error_rates_all_contrasts.png)

A forest plot of the model coefficients clearly shows that the credible intervals for the LR and H effects are far from zero, indicating a high probability of a true effect.

![Forest plot of contrast effects relative to the spelling control baseline. Negative values indicate more errors.](outputs/09_forest_plot_all_contrasts.png)

Most importantly, our continuous model (`accuracy ~ phonological_distinctness_scaled`) directly tested the theoretical mechanism. The results show a clear relationship: as phonological distinctness decreases, the error rate increases, confirming that the L1 phonological inventory is the driving factor.

![The relationship between phonological distinctness and error rate, demonstrating the core mechanism of representational indeterminacy.](outputs/14_representational_distinctness_mechanism.png)

Posterior predictive checks for our primary model show excellent fit, with the density of the observed data (`y`) closely matching the densities of the simulated data from the model (`y_rep`).

![Posterior predictive check for the comprehensive model, showing a close match between observed and simulated data.](outputs/11_posterior_predictive_check.png)

### Group Project Links

*   **GitHub Repository:** [Link to be inserted here]
*   **Statement:** The full analysis code (`TaskA_.r`), data, and outputs are available at the GitHub repository linked above.

### References

[1] Ota, M., Hartsuiker, R. J., & Haywood, S. L. (2009). The KEY to the ROCK: Near-homophony in nonnative visual word recognition. *Cognition*, 111(2), 263–269.

[2] Bürkner, P. C. (2017). brms: An R package for Bayesian multilevel models using Stan. *Journal of Statistical Software*, 80(1), 1-28.
